{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f59712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573823c",
   "metadata": {},
   "source": [
    "### Split Text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33eff7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_overlap_text(text: str, overlap_chars: int) -> str:\n",
    "    \"\"\"Get the last overlap_chars characters, preferring paragraph boundaries.\"\"\"\n",
    "    if len(text) <= overlap_chars:\n",
    "        return text\n",
    "    \n",
    "    # Try to get overlap at paragraph boundary\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    if len(paragraphs) > 1:\n",
    "        # Start with last paragraph and add previous ones if they fit\n",
    "        overlap = paragraphs[-1]\n",
    "        for i in range(len(paragraphs) - 2, -1, -1):\n",
    "            potential_overlap = paragraphs[i] + \"\\n\\n\" + overlap\n",
    "            if len(potential_overlap) <= overlap_chars:\n",
    "                overlap = potential_overlap\n",
    "            else:\n",
    "                break\n",
    "        return overlap\n",
    "    \n",
    "    # Fallback to character-based overlap\n",
    "    return text[-overlap_chars:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e81eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trim_to_sentence_boundary(text: str, max_chars: int) -> str:\n",
    "    \n",
    "    \"\"\"Trim text to last complete sentence within max_chars limit.\"\"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    \n",
    "    # Find the last sentence ending before max_chars\n",
    "    truncated = text[:max_chars]\n",
    "    \n",
    "    # Look for sentence endings (., !, ?)\n",
    "    sentence_endings = ['.', '!', '?']\n",
    "    last_sentence_end = -1\n",
    "    \n",
    "    for i in range(len(truncated) - 1, -1, -1):\n",
    "        if truncated[i] in sentence_endings:\n",
    "            # Make sure it's not an abbreviation or decimal\n",
    "            if i < len(truncated) - 1 and truncated[i + 1].isspace():\n",
    "                last_sentence_end = i\n",
    "                break\n",
    "    \n",
    "    if last_sentence_end > len(text) * 0.5:  # Don't cut too much\n",
    "        return text[:last_sentence_end + 1]\n",
    "    \n",
    "    return text  # Return original if no good boundary found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b649eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_chunk_paragraphs_enhanced(\n",
    "    text: str, \n",
    "    max_chars: int = 500, \n",
    "    overlap_chars: int = 100,\n",
    "    min_chunk_size: int = 50,\n",
    "    preserve_sentence_boundaries: bool = True\n",
    ") -> List[str]:\n",
    "    \n",
    "    if not text.strip():\n",
    "        return []\n",
    "    \n",
    "    # Split into paragraphs, keeping empty lines as separators\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text.strip())\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    overlap_buffer = \"\"\n",
    "    \n",
    "    for i, para in enumerate(paragraphs):\n",
    "        # Check if adding this paragraph would exceed max_chars\n",
    "        potential_chunk = current_chunk + (\"\\n\\n\" if current_chunk else \"\") + para\n",
    "        \n",
    "        if len(potential_chunk) <= max_chars:\n",
    "            current_chunk = potential_chunk\n",
    "        else:\n",
    "            # Current chunk is ready, process it\n",
    "            if current_chunk:\n",
    "                final_chunk = current_chunk\n",
    "                \n",
    "                # Apply sentence boundary preservation if enabled\n",
    "                if preserve_sentence_boundaries and len(final_chunk) > max_chars * 0.8:\n",
    "                    final_chunk = _trim_to_sentence_boundary(final_chunk, max_chars)\n",
    "                \n",
    "                chunks.append(final_chunk)\n",
    "                \n",
    "                # Prepare overlap for next chunk\n",
    "                overlap_buffer = _get_overlap_text(final_chunk, overlap_chars)\n",
    "            \n",
    "            # Start new chunk with overlap + current paragraph\n",
    "            current_chunk = overlap_buffer + (\"\\n\\n\" if overlap_buffer else \"\") + para\n",
    "            overlap_buffer = \"\"\n",
    "    \n",
    "    # Add the last chunk if it exists and meets minimum size\n",
    "    if current_chunk and len(current_chunk.strip()) >= min_chunk_size:\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408ba5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ html_oie_employment_f1-students_curricular-practical-training.txt: 3 chunks\n",
      "✅ html_oie_employment_f1-students_index.txt: 8 chunks\n",
      "✅ html_oie_employment_f1-students_on-campus-employment.txt: 3 chunks\n",
      "✅ html_oie_employment_f1-students_opt-stem-opt-extension_h1b-cap-gap-extension.txt: 4 chunks\n",
      "✅ html_oie_employment_f1-students_opt-stem-opt-extension_i765-instructions.txt: 3 chunks\n",
      "✅ html_oie_employment_f1-students_opt-stem-opt-extension_index.txt: 7 chunks\n",
      "✅ html_oie_employment_f1-students_opt-stem-opt-extension_opt-stem-extension.txt: 3 chunks\n",
      "✅ html_oie_employment_f1-students_opt-stem-opt-extension_post-completion-opt.txt: 3 chunks\n",
      "✅ html_oie_employment_f1-students_opt-stem-opt-extension_pre-completion-opt.txt: 3 chunks\n",
      "✅ html_oie_employment_f1-students_severe-economic-hardship.txt: 9 chunks\n",
      "✅ html_oie_employment_index.txt: 9 chunks\n",
      "✅ html_oie_employment_j1-students_academic-training-employment.txt: 3 chunks\n",
      "✅ html_oie_employment_j1-students_index.txt: 6 chunks\n",
      "✅ html_oie_employment_j1-students_on-campus-employment.txt: 3 chunks\n",
      "✅ html_oie_employment_opt-reporting.txt: 5 chunks\n",
      "✅ html_oie_employment_resources_apply-for-ssn.txt: 3 chunks\n",
      "✅ html_oie_employment_resources_f1-to-h1b-status.txt: 3 chunks\n",
      "✅ html_oie_employment_resources_index.txt: 3 chunks\n",
      "✅ html_oie_employment_resources_replacement-ead-card.txt: 3 chunks\n",
      "✅ html_oie_employment_resources_us-permanent-residency.txt: 7 chunks\n",
      "✅ html_oie_employment_resources_work-authorization.txt: 5 chunks\n",
      "✅ html_oie_employment_scholars_h1b-workers.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_index.txt: 6 chunks\n",
      "✅ html_oie_employment_scholars_j1-scholar-employment-issues.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_j1-scholars.txt: 7 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_b-visitors-visa-waiver.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_b-vs-j-status.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_e3-australians.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_index.txt: 9 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_j2-employment.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_o1-status.txt: 3 chunks\n",
      "✅ html_oie_employment_scholars_other-work-categories_tn-status.txt: 4 chunks\n",
      "✅ html_oie_employment_stem-opt-reporting.txt: 3 chunks\n",
      "✅ html_oie_employment_volunteering.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_index.txt: 5 chunks\n",
      "✅ html_oie_maintaining-status_resources_health-insurance.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_home-residency.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_i539.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_index.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_legal-resources.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_public-charge.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_archive_2020-tax-information.txt: 7 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_archive_2021-tax-information.txt: 7 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_archive_2022-tax-information.txt: 9 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_archive_2023-tax-information.txt: 9 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_index.txt: 5 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_scholars_index.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_resources_tax-information_students_index.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_scholars_extending-status.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_scholars_h1b-maintaining-status.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_scholars_index.txt: 7 chunks\n",
      "✅ html_oie_maintaining-status_scholars_leaving-cmu.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_scholars_time-limits-bars.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_students_course-load-modality.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_students_documents.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_students_extending-i20-ds2019.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_students_index.txt: 7 chunks\n",
      "✅ html_oie_maintaining-status_students_leaving-carnegie-mellon.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_students_loa-suspension-dismissal.txt: 3 chunks\n",
      "✅ html_oie_maintaining-status_students_program-degree-change.txt: 3 chunks\n",
      "✅ html_oie_travel_documents_f1-and-j1-students_index.txt: 3 chunks\n",
      "✅ html_oie_travel_documents_f1-and-j1-students_opt.txt: 3 chunks\n",
      "✅ html_oie_travel_documents_h1b-workers.txt: 3 chunks\n",
      "✅ html_oie_travel_documents_index.txt: 3 chunks\n",
      "✅ html_oie_travel_documents_j1-scholars.txt: 3 chunks\n",
      "✅ html_oie_travel_domestic_drivers-license.txt: 3 chunks\n",
      "✅ html_oie_travel_domestic_index.txt: 3 chunks\n",
      "✅ html_oie_travel_families-dependents_index.txt: 3 chunks\n",
      "✅ html_oie_travel_families-dependents_infant-passport.txt: 3 chunks\n",
      "✅ html_oie_travel_government-agencies_index.txt: 3 chunks\n",
      "✅ html_oie_travel_index.txt: 7 chunks\n",
      "✅ html_oie_travel_visa_automatic-visa-revalidation.txt: 3 chunks\n",
      "✅ html_oie_travel_visa_index.txt: 8 chunks\n",
      "✅ html_oie_travel_visa_renew.txt: 3 chunks\n",
      "✅ html_oie_travel_visa_schengen.txt: 3 chunks\n",
      "✅ html_oie_travel_visa_third-country.txt: 3 chunks\n",
      "✅ html_oie_travel_visa_visa-delay-security-clearance.txt: 4 chunks\n",
      "✅ pdf_collaborating-visitor_documents_collaborating-visitor-questinnaire.txt: 5 chunks\n",
      "✅ pdf_hub_docs_return-loa.txt: 2 chunks\n",
      "✅ pdf_hub_docs_withdrawal.txt: 1 chunks\n",
      "✅ pdf_oie_administrators_docs_immapp.txt: 2 chunks\n",
      "✅ pdf_oie_administrators_docs_insurance.txt: 1 chunks\n",
      "✅ pdf_oie_administrators_docs_permres.txt: 4 chunks\n",
      "✅ pdf_oie_administrators_docs_sample2.txt: 1 chunks\n",
      "✅ pdf_oie_administrators_docs_tn-handout.txt: 2 chunks\n",
      "✅ pdf_oie_docs_academic-training-employer-attestation.txt: 2 chunks\n",
      "✅ pdf_oie_docs_academic-training-j-1.txt: 4 chunks\n",
      "✅ pdf_oie_docs_change-of-college.txt: 1 chunks\n",
      "✅ pdf_oie_docs_change-program.txt: 2 chunks\n",
      "✅ pdf_oie_docs_cpt-advisor-recommendation.txt: 1 chunks\n",
      "✅ pdf_oie_docs_dependent-request-form.txt: 1 chunks\n",
      "✅ pdf_oie_docs_i983-instructions-handout.txt: 5 chunks\n",
      "✅ pdf_oie_docs_immapp.txt: 2 chunks\n",
      "✅ pdf_oie_docs_j-on-camp-fillable.txt: 1 chunks\n",
      "✅ pdf_oie_docs_post-opt-advisor-recommendation.txt: 1 chunks\n",
      "✅ pdf_oie_docs_power-points_employment-authorization-overview.txt: 46 chunks\n",
      "✅ pdf_oie_docs_power-points_opt-pre.txt: 44 chunks\n",
      "✅ pdf_oie_docs_power-points_stem-opt-slides.txt: 56 chunks\n",
      "✅ pdf_oie_docs_pre-opt-academic-advisor-recommendation-form.txt: 1 chunks\n",
      "✅ pdf_oie_docs_program-extension.txt: 2 chunks\n",
      "✅ pdf_oie_docs_reduced.txt: 1 chunks\n",
      "✅ pdf_oie_docs_request-services.txt: 1 chunks\n",
      "✅ pdf_oie_docs_sample-i765-pre-post.txt: 7 chunks\n",
      "✅ pdf_oie_docs_scholar-data.txt: 1 chunks\n",
      "✅ pdf_oie_docs_sevis-fee.txt: 2 chunks\n",
      "✅ pdf_oie_docs_ssdirect.txt: 2 chunks\n",
      "✅ pdf_oie_docs_ssn-form-externalvendor.txt: 2 chunks\n",
      "✅ pdf_oie_docs_ssn-form.txt: 2 chunks\n",
      "✅ pdf_oie_docs_updatedsample_employer_offer_letter_cpt.txt: 2 chunks\n",
      "✅ pdf_oie_foreign-students_docs_grad-affidavit-of-support.txt: 1 chunks\n",
      "✅ pdf_oie_foreign-students_docs_reduced.txt: 1 chunks\n",
      "✅ pdf_oie_foreign-students_docs_sample-job-duties-descriptions.txt: 1 chunks\n",
      "✅ pdf_oie_foreign-students_docs_undergrad-affidavit-updated.txt: 1 chunks\n",
      "✅ pdf_oie_travel_visa_us-visa-in-canada.txt: 2 chunks\n",
      "\n",
      "📦 Total chunks: 533\n"
     ]
    }
   ],
   "source": [
    "# Store all Document chunks\n",
    "all_documents = []\n",
    "\n",
    "cleaned_folder = \"../cmu_oie_scrape/cleaned\"\n",
    "\n",
    "for filename in os.listdir(cleaned_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(cleaned_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_text = f.read()\n",
    "\n",
    "        chunks = dynamic_chunk_paragraphs_enhanced(file_text, max_chars=200, overlap_chars=50)\n",
    "        \n",
    "        # Tag documents with metadata (e.g., source file)\n",
    "        docs = [Document(page_content=chunk, metadata={\"source\": filename}) for chunk in chunks]\n",
    "        all_documents.extend(docs)\n",
    "\n",
    "        print(f\"✅ {filename}: {len(chunks)} chunks\")\n",
    "\n",
    "print(f\"\\n📦 Total chunks: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723c0e9",
   "metadata": {},
   "source": [
    "### Creating embeddings from chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffa26da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhong\\AppData\\Local\\Temp\\ipykernel_12932\\2253163745.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-cos-v1\")\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ee263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(all_documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "176ad7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FAISS index saved to: ../vectorstore/faiss_index\n"
     ]
    }
   ],
   "source": [
    "# Save the vectorstore to disk\n",
    "\n",
    "vectorstore_path = \"../vectorstore/faiss_index\"\n",
    "os.makedirs(vectorstore_path, exist_ok=True)\n",
    "\n",
    "vectorstore.save_local(vectorstore_path)\n",
    "print(f\"\\n FAISS index saved to: {vectorstore_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0768033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
